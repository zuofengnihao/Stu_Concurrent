# Stu_Concurrent

## 第1章 并发编程的挑战

### 1.1 上下文切换
当前线程要切换到另外一个线程的时候，需要保存当先线程的状态（如：寄存器里面已经计算好了的值，当前运行到哪段代码了等信息），然后读取或叫加载另外那个线程的状态，这就是上下文的切换。

#### 1.1.1 多线程一定快吗
不一定，因为线程有创建和上下文切换的开销。

#### 1.1.2 测试上下文切换次数和时长
* 使用Lmbench可测量上下文切换带来的消耗
* 使用vmstat可测量上下文切换的次数

#### 1.1.3 如何减少上下文的切换
1. 使用无锁并发编程：多线程竞争锁，会引起上下文的切换。可以使用一些办法避免使用锁。如：将数据ID按照Hash算法取模来分段，不同线程处理不同段的数据。
2. CAS算法：Atomic包使用CAS算法，不需要加锁。
3. 使用最少的线程：避免创建不需要的线程。
4. 协程：我理解的协程就是在用户态使用代码实现的多线程，和内核态的线程是一对多的关系。协程不需要切换到内核态来完成任务的调度与切换。当然协程也是需要记录和切换上下文的，只是在用户态中，程序员是自己可以用代码来压榨切换带来的最小开销极限。

#### 1.1.4 减少上下文切换实战
* 第一步：用jstack命令dump线程信息。
* 第二步：统计线程状态。
* 第三步：打开dump文件查看处于WAITING的线程在做什么。
* 第四步：减少无效的WAITING状态的线程数量。

### 1.2 死锁
避免死锁的常见方法：
1. 避免一个线程同时获取多个锁。
2. 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源。
3. 尝试使用定时锁，lock.tryLock(timeout)。
4. 对于数据库锁，加锁和解锁必须在一个数据库链接里。

### 1.3 资源限制的挑战

1. 什么是资源限制  
2. 资源限制引发的问题
3. 如何解决资源限制
4. 在资源限制情况下进行并发

### 1.4 本章小结

## 第2章 Java并发机制的底层实现原理

Java中所使用的并发机制依赖于JVM的实现和CPU的指令。

### 2.1 Volatile的应用

在多处理器开发中保证了共享变量的“可见性”。

#### 2.1.1 Volatile的定义与实现原理

定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一直的更新，线程应该确保通过排它锁单独获得这个变量。  

CPU的相关术语：
* 内存屏障（Memory barriers）：是一组处理器指令，用于实现对内存操作的顺序限制。
* 缓冲行（cache line）：缓存中可分配的最小存储单位。处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期。
* 原子操作（atomic operations）：不可中断的一个或一系列操作。
* 缓存行填充（cache line fill）：当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存（L1/L2/L3）。
* 缓存命中（cache hit）：如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存中。
* 写命中（write hit）：当处理器将操作数写回到一个内存缓存的区域时，它会首先检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则处理器将这个操作数写回到缓存，而不是写回到内存，这个操作被称为写命中。
* 写缺失（write misses the cache）：一个有效的缓存行被写入到不存在的内存区域。  

原理：如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。通过实现缓存一致性协议（MESI）每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。

#### 2.1.2 Volatile的使用优化

避免伪共享（false sharing）：Doug Lea 使用追加字节的方式来优化。

### 2.2 Synchronized的实现原理与应用

Synchronized同步代码块是使用monitorenter和monitorexit指令实现的。同步方法是另一种方式实现。

锁对象的三种形式：
1. 普通同步方法，锁是当前的实例对象。
2. 静态同步方法，锁是当前类的Class对象。
3. 同步代码块，锁是Synchronized括号中里配置的对象。

#### 2.2.1 Java对象头

* Mark Word 32/64bit 存储对象的hashCode或锁信息等  
* Class Metadata Address 32/64bit 存储到对象类型数据的指针  
* Array Length 32/32bit 数组长度（如果当前对象是数组）  

64位虚拟机 Mark Word：
* 1bit 是否偏向锁 
* 2bit 锁标志位
* 4bit GC分代年龄
* 31bit hashcode    
* 25bit unused

#### 2.2.2 锁定升级与对比

1. 偏向锁：  
   进入同步代码块，检查锁对象头markword是否有锁（锁标志位或是否偏向锁）。  
   * 如果是无锁状态  
     * 检查是否开启偏向锁  
       * 开启，cas修改markword偏向当前线程
          * 修改成功，执行同步代码块
          * 修改失败，先暂停偏向的线程，检查线程是否退出同步代码块
            * 退出，撤销偏向锁，唤醒原持有锁的线程
            * 未退出，升级为轻量级锁
       * 未开启，轻量级锁流程...
   * 有锁状态，是否为偏向锁
     * 是偏向锁，检查偏向线程是否为当前线程
       * 是，执行同步代码块
       * 否，cas修改markword偏向当前线程
         * 修改成功，执行同步代码块
         * 修改失败，先暂停偏向的线程，检查线程是否退出同步代码块 
           * 退出，撤销偏向锁，唤醒原持有锁的线程
           * 未退出，升级为轻量级锁
      * 否，按照当前锁的方法来执行 

2. 轻量级锁
   进入同步代码块，检查是否为偏向锁升级
   * 是偏向是升级，为偏向线程的栈中分配锁记录
   * 不是偏向锁升级，为当前线程的栈中分配所记录  
   
   CAS操作，将对象头中的markword复制到锁记录中，displaced mark word
   * 操作成功，markword指向当前线程的锁记录中，执行同步代码块，执行完毕后cas修改markword（改回）
     * 成功，解锁完成
     * 失败，升级重量级锁
   * 操作失败，自旋等待
     * 多次自选失败，升级重量级锁
       
3. 锁的优缺点  
   
   偏向锁：适用于只有一个线程访问的场景。优点是加锁一次cas操作，缺点是如果线程参在额外竞争会带来额外的撤销锁的消耗。  
   
   轻量级锁：适用于同步块执行速度快的场景。优点是竞争的线程不会阻塞，缺点是cup自旋消耗。  
   
   重量级锁：适用于追求吞吐量，同步代码块执行长。优点不会消耗cpu，缺点就是阻塞线程，响应慢。
   
### 2.3 原子操作的实现原理

1. 处理器如何实现原子操作
   * 使用总线加锁
   * 使用缓存加锁

2. Java如何实现原子操作
   * 使用循环CAS实现（自旋锁）  
     Cas操作的三大问题
     1. ABA问题，解决：在参数中加入版本号
     2. 循环时间长开销大
     3. 只能保证一个共享变量的原子操作，解决：同步块 
   * 使用锁机制实现原子操作：偏向锁，轻量级锁，重量级锁。JVM实现锁的方式都用到了CAS操作，即获取锁和释放锁时。

### 2.4 本章小结

## 第3章 Java内存模型

### 3.1 Java内存模型的基础

#### 3.1.1 并发编程模型的两个关键

线程之间如何通信及线程间如何同步？  

线程间的通讯有两种机制：
1. 共享内存：共享内存的线程间通讯是隐式的，同步则是显式的。
2. 消息传递：消息传递的线程间通讯是显示的，同步则是隐式的。  

Java的并发采用的是共享内存的方式。

#### 3.1.2 Java内存模型的抽象结构

线程之间的共享变量存储在主存中，每个线程都有一个私有的本地内存，本地内存中存储了该线程以读/写的共享变量的副本。本地内存是JMM的一个抽象概念，它涵盖了缓存、写缓冲区、寄存器以及其他的硬件和编译优化。  

如果线程A与线程B之间要通讯的话，必须要经历2个步骤：
1. 线程A把本地内存A中更新过的共享变量刷新到主存中。
2. 线程B到主存中读取线程A之前更新变量。  

从整体上看，这两个步骤实质上是线程A向线程B发送消息，而这个通信过程必须要经过主存。JMM通过控制主存与每个线程的本地内存之间的交互来为JAVA程序员提供内存可见性保证。

#### 3.1.3 从源代码到指令序列的重排序

为了提高性能，编译器和处理器常常会对指令做重排序。分为3重类型：
1. 编译器优化的重排序。
2. 指令级并行重排序。
3. 内存系统的重排序。

1属于编译器重排序，2和3属于处理器重排序。  
JMM的编译器重排序规则会禁止特定类型的编译器重排序。而对于处理器重排序，会在生成指令序列时，插入特定类型的内存屏障来禁止。

#### 3.1.4 并发编程模型的分类

现代处理器使用写缓冲区临时存放向内存写入的数据。每个写缓冲区只对该核心可见，这个特性会对内存操作顺序产生重要的影响！  
例：int x = 0 在主存中，线程A执行 x = 1，然后线程B执行 print(x),打印结果可能会为“0”，因为线程A写入数据时写入的是缓存区，而线程B读取的是主存中的数据。在我们看来，像是线程B先于线程A执行了，即写读变成了读写。因此，大部分处理器都支持写读操作的重排序。

为了保证可见性，Java编译器在生成指令序列的适当位置会插入内存屏障指令来禁止特定类型的处理器的重排序。JMM把内存屏障分为4类。
1. LoadLoad Barriers `Load1;LoadLoad;Load2`：确保Load1数据的装载先于load2及后续装在指令的装在
2. StoreStore Barriers `Store1;StoreStore;Store2`：确保Store1数据对其他处理器可见（刷新回主存）先于Store2
3. LoadStore Barriers `Load1;LoadStore;Store2`：确保Load1数据装载先于Store2
4. StoreLoad Barriers `Store1;StoreLoad;Load2`：确保Store1数据对其他线程可见，先于Load2。该屏障之前的所有内存访问指令完成后，才执行该屏障之后的内存访问指令。StoreLoad Barriers是一个全能型的屏障，它同时具有以上3个屏障的效果。执行该屏障开销会很昂贵，因为当前处理器通常要把写缓冲区中的数据全部刷新到内存中。

#### 3.1.5 happens-before简介

从JDK5开始，Java使用新的JSR-133内存模型。JSR-133使用happens-before的概念来阐述操作之间的内存可见性。如果一个操作执行的结果需要另一个操作可见，那么这两个操作之间必须存在happens-before关系。
* 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
* 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
* volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
* 传递性：如果A happens-before B，B happens-before C，则A happens-before C。

注意：两个操作之间具有happens-before原则不代表前一个操作必须在后一个操作之前执行！happens-before仅仅要求前前一个操作执行结果对后一个操作可见，且前一个操作按顺序排在第二个操作之前。

对于Java程序员来说，happens-before规则简单，它避免了我们为了理解JMM提供的内存可见性保证而去学习复杂的重排序规则以及这些规则的具体实现方法。

### 3.2 重排序

重排序是指编译器和处理器为了优化程序性能而对指令序列重新排序的一种手段。

#### 3.2.1 数据依赖性

如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时两个操作之间就存在数据依赖性。数据依赖性分为一下3种
1. 写后读 `a=1;b=a;` 写一个变量之后，再读这个变量。
2. 写后写 `a=1;a=2;` 写一个变量之后，再写这个变量。
3. 读后写 `a=b;a=1;` 读一个变量之后，再写这个变量。

以上3种操作，只要重排序两个操作的顺序，程序的执行结果就会改变。  
这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作。不同处理器线程之间的数据依赖性不被编译器和处理器考虑。

#### 3.2.2 as-if-serial语义

意思：不管怎么重排序，单线程程序的执行结果不能改变。编译器、runtime和处理器都必须遵守as-if-serial。  
as-if-serial语义把单线程程序保护了起来，使程序员产生了幻觉：单线程程序是按程序的顺序来执行的。

#### 3.2.3 程序顺序规则

在不改变程序执行结果的前提下，尽可能提高并行度。编译器和处理器遵从这一目标，从happens- before的定义我们可以看出，JMM同样遵从这一目标。  

#### 3.2.4 重排序对多线程的影响

1. 重排序会破坏多线程的语义。
2. 在单线程中，对存在控制依赖的操作重排序不会改变执行结果。但在多线程中，存在控制依赖的操作重排序，可能会改变程序的执行结果。

### 3.3 顺序一致性

顺序一致性内存模型是一个理论参考模型，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。

#### 3.3.1 数据竞争与数据一致性

如果程序是正确同步的，程序的执行将具有顺序一致性。

#### 3.3.2 顺序一致性模型

两大特性：
1. 一个线程中所有操作必须按照程序的顺序执行。
2. （不管程序是否同步）所有线程都只能看到一个单一的操作执行顺序，每个操作都必须原子执行且立刻对所有线程可见。

#### 3.3.3 同步程序的顺序一致性效果

这是一个正确同步的多线程程序。根据JMM规范，该程序的执行结果将与该程序在顺序一致性模型中的执行结果相同。  
JMM在具体实现上的基本方针为：在不改变（正确同步的）程序执行结果的前提下，尽可能地为编译器和处理器的优化打开方便之门。

#### 3.3.4 未同步程序的执行特性

JMM只提供最小安全性：线程执行时读取到的值，要么就是之前某个线程写入的，要么是默认值。  

JMM与顺序一致性的差异：
1. 顺序一致性保证单线程内的操作会按程序的顺序执行，JMM不能保证。
2. 顺序一致性模型保证所有线程只能看到一致的操作执行顺序，JMM不能保证。
3. JMM不保证对64位数据的写操作具有原子性，顺序一致性保证所有的内存读/写都是原子的。

### 3.4 volatile的内存语义

#### 3.4.1 volatile的特性

* 可见性：对一个volatile变量的读，总是能看到对这个volatile变量最后的写入。
* 原子性：对任意单个volatile变量的读/写具有原子性， 但类似++这种复合操作不具备原子性。

#### 3.4.2 volatile写-读建立的happens-before关系

从JSR-133开始，volatile变量的读写可以实现线程之间的通信。  
volatile的写-读，与锁的释放-获取有相同的内存效果。

#### 3.4.3 volatile写-读的内存语义

volatile写语义：当写一个volatile变量时，JMM会把该线程对应的本地内存中的共享变量值刷新到主存中。  
volatile读语义：当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效，线程接下来将从主存中读取共享变量。

* 线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了消息。
* 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的消息。
* 线程A写一个volatile变量，随后线程B读这个变量，实质上是线程A通过主存向B发送消息。

#### 3.4.4 volatile内存语义的实现

* 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则保证volatile写之前的操作不会被编译器重排序到volatile写之后。
* 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序到volatile读之前。
* 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。

内存屏障：
* 在每个volatile写操作之前插入一个StoreStore屏障。
* 在每个volatile写操作之后插入一个StoreLoad。
* 在每个volatile读操作之后插入一个LoadLoad屏障。
* 在每个volatile读操作之前插入一个LoadStore。

在X86处理器中，仅会对写-读操作做重排序。因此JMM仅需在volatile写后面插入一个StoreLoad屏障。

#### 3.4.5 JSR-133为什么增强volatile内存语义

因为volatile的写-读没有锁的释放-获取具有的内存语义。

### 3.5 锁的内存语义

#### 3.5.1 锁的释放-获取建立的happens-before关系
与volatile写-读相似

#### 3.5.2 锁的释放和获取的内存语义
与volatile写-读相似 实际上是线程A向线程B发送消息。

#### 3.5.3 锁内存语义的实现

以ReentrantLock的源码为例
公平锁的加锁（获取锁）是读取一个volatile变量（state），公平锁的释放锁是写volatile变量state。
非公平锁的加锁（获取锁）是CAS操修改state变量，非公平锁的释放也是volatile变量的写操作。

CAS如何同时具有volatile读和写的内存语义的：
CAS源码指令cmpxchg，如果是多核处理器程序会给cmpxchg指令加上lock前缀：lock cmpxchag

lock指令前缀：
1. 确保对内存的读-改-写操作原子执行。
2. 禁止该指令与之前和之后的指令重排序。
3. 把写缓冲区的所有数据刷新到内存中。  

上了面2.3点所具有的内存屏障效果，足以实现volatile读和写。

#### 3.5.4 concurrent包的实现

Java线程间通信有4中方式：
1. A线程写volatile变量，B线程读volatile变量
2. A线程写volatile变量，B线程CAS操作volatile变量
3. A线程CAS操作volatile变量，B线程读volatile变量
4. A线程CAS操作volatile变量，B线程CAS操作volatile变量

volatile变量的读/写和CAS可以实现线程间的通讯，把这些整合在一起就形成了concurrent包的基石。

### 3.6 final域的内存语义

#### 3.6.1 final域的重排序

对于final域，编译器处理器要遵循两个重排序规则：
1. 在构造函数内对一个final域的写入，与随后把这个对象的引用赋值给一个引用变量，这两个操作之间不能重排序
2. 初次读一个包含final域的对象的引用时，与随后初次读这个final域，这两个操作之间不能重排序。

例子：见chapter3.FinalExample

#### 3.6.2 写final域的重排序规则

规则的实现包含2个方面：
1. JMM禁止编译器把final域的写重排序到构造函数之外。
2. 编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。这个屏障禁止处理器把final域的写重排序到构造函数之外。

#### 3.6.3 读final域的重排序规则

在一个线程中，初次读对象引用与初次读该对象包含的final域，JMM禁止处理器重排序这两个操作。编译器会在读final域操作之前插入一个LoadLoad屏障。（只针对处理器，我们自己编码的时候都是用对象.属性的方式，在程序员看来是遵循happens-before原则的，这是说的底层实现）

#### 3.6.4 final域为引用类型

例子：见chapter3.FinalReferenceExample

对于引用的对象，写final域的重排序规则对编译器和处理器增加了如下约束：  
在构造函数内对一个final引用的对象的成员域的写入，与随后在构造函数外把这个构造对象的引用赋值给一个引用变量，这两个操作之间不能重排序。

#### 3.6.5 为什么final引用不能从构造函数内“溢出”

在构造函数内部，不能让这个被构造的对象的引用为其他线程所见，也就是对象引用不能在构造函数中“溢出”。

#### 3.6.6 final语义在处理器中的实现

由于X86处理器不会对写-写做重排序，所以会省略掉写fianl域的StoreStore屏障。同样，由于X86处理器不会对存在间接依赖关系的操作做重排序，所以读final域的LoadLoad操作也会被省略。也就是说，在X86处理器中，final域的读写都不会插入任何内存屏障。

#### 3.6.7 JSR-133为什么要增强final语义

因为旧的内存模型中，线程可能看到final域的值会改变。（默认值0 -> 构造复制1）  
为了修复漏洞：只要对象正确的构造，被构造对象的引用在构造函数中没有“逸出“。

### 3.7 happens-before

#### 3.7.1 JMM的设计

设计JMM需要考虑两个因素：
1. 程序员对内存模型的使用。易于理解，易于编程，强内存模型
2. 编译器处理器对内存模型的实现。束缚越少越好，弱内存模型

策略：
1. 对于会改变程序执行结果的重排序，JMM禁止。
2. 对于不会改变执行结果的重排序，JMM允许。

#### 3.7.2 happens-before的定义

1. 一个操作happens-before另一个操作，那么第一个操作的执行结果将对第一个操作可见，而且第一个操作在第二个操作之前。
2. 两个操作存在happens-before关系，并不意味着必须按照制定顺序进行，只要重排序后执行结果相同。

#### 3.7.3 happens-before规则

1. 程序顺序规则：一个线程中的每个操作，happens-before于该线程的任意后续操作。
2. 监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
3. volatile变量规则：对一个volatile域的写，happens-before于任意后续对这个volatile域的读。
4. 传递性：A hb B -> B hb C -> A hb C
5. start()规则：线程的start()操作happens-before于线程中的任意操作。
6. join()规则：线程的任意操作happens-before线程的join()操作。

### 3.8 双重检查锁定与延迟初始化

#### 3.8.1 双重检查锁定的由来

典型例子：懒加载的单例模式

例子：chapter3.UnsafeLazyInitialization/SafeLazyInitialization/DoubleCheckLocking

#### 3.8.2 问题的根源

见例子：chapter3.DoubleCheckLocking

#### 3.8.3 volatile解决方案

例子：chapter3.SafeDoubleCheckedLocking

#### 3.8.4 给予初始化的解决方案

例子：chapter3.InstanceFactory

### 3.9 Java内存模型综述

#### 3.9.1 处理的内存模型

| 内存模型 | 对应的处理器 | Store-Load重排序 | Store-Store重排序 | Load-Load/Load-Store重排序 | 可以更早读取到其他处理器的写 | 可以更早读取到当前处理器的写 |
| TSO | sparc-TSO x64 | Y | ~ | ~ | ~ | Y |
| PSO | sparc-PSO | Y | Y | ~ | ~ | Y |
| RMO | ia64 | Y | Y | Y | ~ | Y |
| PowerPC | PowerPC | Y | Y | Y | Y | Y |  

从上表中看出所有处理器都允许 写-读 重排序。它们都使用了写缓冲区。  
同时都允许更早读到当前处理器的写，原因也是写缓冲区。由于写缓冲区只对当前处理器可见，这个特性可以导致当前处理器比其他处理器先看到临时保存在自己缓冲区中的写。  

JMM在不同处理器平台插入的内存屏障：
* TSO内存模型`sparc-TSO X86` `StoreLoad`  
* PSO内存模型`sparc-PSO` `StoreLoad StoreStore`
* RMO/PowerPC内存模型`ia64 PowerPC` `StoreLoad StoreStore LoadStore LoadLoad`

#### 3.9.2 各种内存模型之间的关系

* JMM是一个语言级的内存模型
* 处理器内存模型是硬件级的内存模型
* 顺序一致性内存模型是一个参考模型

处理器内存模型比语言内存模型弱，语言内存模型比顺序一致性内存模型弱。越弱越易于编程，但性能越差。

#### 3.9.3 JMM的内存可见性保证

1. 单线程不会出现内存可见性问题。
2. 正确同步的多线程将具有顺序一致性。
3. 未同步/未正确同步的多线程，JMM提供最小安全性保障：要么是前一个线程的写入，要么是默认值(0,null,false)

#### 3.9.4 JSR-133对旧的内充模型的修补

1. 增强volatile的内存语义
2. 增强final的内存语义

### 3.10 本章小结

## 第4章 Java并发编程基础

### 4.1 线程简介

#### 4.1.1 什么是线程

操作系统调度的最小单元是线程，也叫轻量级进程。

#### 4.1.2 为什么要使用多线程

1. 更多的处理器核心
2. 更快的响应时间
3. 更好的编程模型

#### 4.1.3 线程优先级

操作系统采用时分的形式调度运行线程，分出一个个的时间片，线程会分配到若干个时间片，当时间片用完了就会发生线程的调度，并等待下次分配。
线程能分配多少时间片决定了使用处理器资源的多少，而线程优先级就是决定线程分配处理器资源的属性。  

Java线程中，通过变量`priority`来控制优先级，范围1~10。在创建线程的时候可以通过`setPriority(int)`方法来修改优先级，默认是5，优先级高的线程分配时间片数量比低的多。

`!注意*` 程序的正确性不能依赖优先级！！！！

`例: chapter4.Priority.java`

#### 4.1.4 线程的状态

* NEW:初始状态，线程被构建，但还没有调用start()
* RUNNABLE:运行状态，Java线程将操作系统中的就绪和运行两种状态笼统的称作“运行中”
* BLOCKED:阻塞状态，表示线程阻塞于锁
* WAITING:等待状态，表示线程进入等待状态，进入该状态表示当前线程需要等待其他线程做出一些特定动作（通知或中断）
* TIME_WAITING:超时等待，该状态与WAITING不同，它是可以在指定时间自行返回
* TERMINATED:终止状态，表示当前线程已经执行完毕

线程创建之后，调用start()方法开始运行。当线程执行wait()方法之后，线程进入等待状态。进入等待状态的线程需要依靠其他线程的通知才能够返回到运行状态，而超时等待状态相当于在等待状态的基础上增加了超时限制，也就是超时时间到达时将会返回到运行状态。当线程调用同步方法时，在没有获取到锁的情况下，线程将会进入到阻塞状态。线程在执行Runnable的run()方法之后将会进入到终止状态。

`例: chapter4.ThreadState.java`

#### 4.1.6 Daemon线程

Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。  

Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。Daemon线程被用作完成支持性工作，但是在Java虚拟机退出时Daemon线程中的finally块并不一定会执行。  

### 4.2 启动和终止线程

start()方法进行启动，随着run()方法的执行完毕，线程也随之终止。

#### 4.2.1 构造线程

一个新构造的线程对象是由其parent线程来进行空间分配的，而child线程继承了parent是否为Daemon、优先级和加载资源的contextClassLoader以及可继承的ThreadLocal，同时还会分配一个唯一的ID来标识这个child线程。

#### 4.2.2 启动线程

调用start()方法就可以启动这个线程。线程start()方法的含义是：当前线程（即parent线程）同步告知Java虚拟机，只要线程规划器空闲，应立即启动调用start()方法的线程。

#### 4.2.3 理解中断

其他线程调用了当前线程的`interrupt()方法`。检查是否被中断调用当前线程的方法`tread.isInterrupted()`。检查当前线程是否被中断，并清楚标志位调用静态方法`Tread.interrupted()`。  
* interrupt() 设置中断标志。
* isInterrupted() 检查中断标志。
* interrupted() 检查标志并清除标志。

`例子 c4.TestInterrupt`

#### 4.2.4 过期的suspend() resume() stop()

`suspend()` 占用锁 容易死锁  
`stop()` 不释放资源

#### 4.2.5 安全的终止线程

1. 使用中断操作
2. boolean信号量

`例子 c4.StopThreadDemo.java`  

### 4.3 线程间的通信

#### 4.3.1 volatile和synchronized

